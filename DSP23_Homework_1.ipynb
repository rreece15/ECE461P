{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QDMxPNTM-8Ew"
      },
      "source": [
        "## EE 461P: Data Science Principles  \n",
        "### Assignment 1  \n",
        "### Total points: 75\n",
        "### Due: Tuesday, January 31, 2023, submitted via Canvas by 11:59 pm  \n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UT eID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TAs know.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "### Name(s) and EID(s):\n",
        "1. Reece Riherd, rdr2793\n",
        "2. (if applicable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l4ZpGDS0bVI"
      },
      "source": [
        "# Question 1 (5 points)\n",
        "\n",
        "Read [this](https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated) article that talks about the possibility of vaccines being uneffective in Israel since nearly 60% of severe COVID-19 hospitalization in Israel were vaccinated people. Use Simpson's Paradox to briefly explain if this claim holds true.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qaijrS9q8_go"
      },
      "source": [
        "# Answer 1\n",
        "\n",
        "When applying Simpson's Paradox to the claim that vaccines are ineffective in Israel, the claim is refuted by the reversal of the trend when data among specific age groups is compared. Although vaccines only show 67.5% efficacy when analyzed with every age group, efffectiveness is consistently shown in the range of 88.7% and 100% for most age groups when analyzed individually. This in combination with factors that influence the disparity of severe Covid cases like age disparity, high rates of vaccination, and a higher likelihood to vaccinate in older generations creates confusion in the interpretation of the data. The apparency of the effectiveness of vaccination is diminished by these external factors, but when these factors are separated (such as by age groups), the effectiveness of vaccination is obvious, thus showing a clear example of Simpson's Paradox."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNBbUfy9Fxqg"
      },
      "source": [
        "# Question 2 (10 points)\n",
        "\n",
        "100 students in the previous offering of this class were asked if they wanted to form their own groups for the course project or have the instructor randomize the groups. They reported their preferences by entering Yes or No in the survey. We use 0 to represent preferring their own groups and 1 to represent randomized groups. A random sample of 20 students yielded the following preferences:\n",
        "\n",
        "$$1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1$$\n",
        "\n",
        "These choices are assumed to arise by independent and identically distributed (i.i.d.) sampling from the following distribution and if the unknown parameter $q$ can be estimated, then we can provide more insights about the students' preference regrading the project groups.\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\nonumber P(x) = \\left\\{\n",
        "\\begin{array}{l l}\n",
        "    q& \\quad \\text{for  } x=0\\\\\n",
        "1-q & \\quad \\text{for } x=1\n",
        "\\end{array} \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Based on the definitions given above, identify the likelihood function and derive the **maximum likelihood estimator** of $q$. Using the given sample, find a maximum likelihood estimate of $q$ as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ_Kz4VN9Dus"
      },
      "source": [
        "# Answer 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHBVQzeVPs02"
      },
      "source": [
        "# Question 3 (5+5 points)\n",
        "\n",
        "a) Briefly explain what you understand by an estimator of a numeric quantity being unbiased? Show that the MLE for the variance of a Gaussian is biased.\n",
        "\n",
        "b) Suppose the mean of the Gaussian distribution, $\\mu$. So given a data set assumed to be obtained by sampling i.i.d from this Gaussian, your job is to obtain the MLE for the unknown variance. Derive the equation for this estimate and show that it is unbiased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UovxZfi8Pt7N"
      },
      "source": [
        "# Answer 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqV_7myxCupC"
      },
      "source": [
        "# Question 4 (5+5 points)\n",
        "\n",
        "a) What is multicollinearity in the context of linear regression and why is it problematic?\n",
        "\n",
        "b) How do you diagnose and fix multicollinearity?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2a5wCF9C7Vw"
      },
      "source": [
        "# Answer 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utv1wVSwk27i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8M2y37dATTO"
      },
      "source": [
        "# Question 5 : Regression (40 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIeme-FoAWxH"
      },
      "source": [
        "### 5.1 Generate Data (5 points)\n",
        "Generate a synthetic regression dataset using make_regression from [sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) with the following characteristics :\n",
        "n_samples = 20000, n_features = 20, n_informative = 15, n_targets = 1, coef = True and random_state = 42, bias = True, noise = 0.1.\n",
        "\n",
        "**Reading Assignment** : Read about how this data is generated and the affect of the above mentioned parameters on the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TYOT8DJcAX7q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[ 0.08177148, -0.25347152, -0.28811056, ...,  1.00114153,\n",
            "        -0.72921777,  0.05173701],\n",
            "       [-0.95896483,  1.74627665, -1.09588119, ...,  0.86306801,\n",
            "         0.29078206, -2.01921959],\n",
            "       [ 0.11251355,  0.54599902, -1.2794076 , ...,  1.88470349,\n",
            "         2.23346905,  0.21025421],\n",
            "       ...,\n",
            "       [-0.95075581,  0.49195521,  0.27607145, ...,  1.89166025,\n",
            "        -0.03713441,  1.14737737],\n",
            "       [ 1.62609356, -1.37429412,  0.25486484, ..., -0.41710534,\n",
            "         2.07025259,  0.92285852],\n",
            "       [ 0.07279916, -1.03061257, -0.32986391, ...,  0.42618969,\n",
            "         0.83310471, -1.83938961]]), array([  53.9603844 , -121.26893563,  266.45803439, ...,  309.85003894,\n",
            "        324.08564947, -305.47342322]), array([49.75788258, 90.83665798, 25.02841944,  0.        ,  4.60361603,\n",
            "       30.85350704,  0.        , 93.84635499, 56.30241747, 65.6311587 ,\n",
            "       17.00530636,  0.        , 31.35960057,  0.        , 60.7651503 ,\n",
            "       54.96244433, 28.80887553,  0.        , 87.80872023, 96.00842932]))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "data = make_regression(n_samples=20000, n_features=20, n_informative=15, n_targets=1, bias=True, noise=0.1, coef=True, random_state=42)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI4XeUtjAYgc"
      },
      "source": [
        "### 5.2 Perform Regression (10 points)\n",
        "a) Divide the above obtained data into a train/test split by using 20% of the data for testing. Then train a linear regression model using Ordinary Least Squares method from [sklearn](https://scikit-learn.org/stable/modules/linear_model.html). \n",
        "\n",
        "b) Evaluate the trained model using Mean Squared Error on both train and test datasets and report the performance. \n",
        "\n",
        "c) Also, print the coefficients and bias obtained after the fit and compare them with the coefficients and bias that were used for generating the data in 5.1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0joZZhB_AbR3"
      },
      "outputs": [],
      "source": [
        "# a.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# b.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# c.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzF7qSSAbf5"
      },
      "source": [
        "### 5.3 Residuals (5 points)\n",
        "a) Compute the residuals (difference between predicted and original values)  of the trained model on the test data. Compute and show the mean and variance of the residuals. \n",
        "\n",
        "b) Scatter plot the residuals along with true predictions and observe how are the residuals distributed.\n",
        "\n",
        "(BONUS) How do the above observations relate to one of the asumptions behind the MLR model? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xujyYrCEAd1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJPQpojJAeAa"
      },
      "source": [
        "### 5.4 Lasso and Ridge Regression (10 points)\n",
        "\n",
        "a) Run Lasso and Ridge regression on the data generated in 5.1 by varying the parameter alpha from 10^-3 to 10^3. For each value of the alpha, store the train error (MSE), test error (MSE), and norm of the coefficient vector using [numpy.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
        "\n",
        "b) Plot the train error, test error and the norm of the coefficient vector with increasing alpha and note what you observe. Use one plot for train error and test error and another for the norm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDT3C9W7j4QW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWbeD15fRXdl"
      },
      "source": [
        "### 5.5 Real-world Regression Problem (10 points)\n",
        "\n",
        "The dataset in the file ecommerce_dataset.csv is for an ecommerce business trying to predict the annual amount spent by each customer. Use Lasso and Ridge regression on the set of independent variables {Average Session Length, Time on App, Time on Website, Length of Membership}  to predict the dependent variable **Yearly Amount Spent**. Vary the value of alpha in the range 10^-6 to 10^5 and do 5-fold cross-validation using sklearn's KFold to find the value of alpha that gives best performance as measured using MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snk9yvieSX5d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QDMxPNTM-8Ew",
        "NNBbUfy9Fxqg",
        "yHBVQzeVPs02"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8cfd1dbc86f0b534087d5775aced4d577639a512f2a900367d7563c49234461"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
